# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f4Kw_0QPsVKrwbi_7WgtokQObSrRPB2w
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
import transformers
from transformers import AutoModel, BertTokenizerFast

# specify GPU
device = torch.device("cuda")

df=pd.read_csv('/content/dataset.csv')

df.head()

x=df['Example']
y=df['Idiom']

from sklearn.model_selection import train_test_split

# First split: Splitting the data into 60% training and 40% into temp (which will be divided into validation and test)
X_train, X_temp, Y_train, Y_temp = train_test_split(x, y, test_size=0.4, random_state=42)

# Second split: Splitting the temp data into validation and test sets (50% each of the temp data)
X_val, X_test, Y_val, Y_test = train_test_split(X_temp, Y_temp, test_size=0.5, random_state=42)

# Now, you have:
# X_train, Y_train - for training
# X_val, Y_val - for validation
# X_test, Y_test - for testing

bert = AutoModel.from_pretrained('bert-base-uncased')

tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')

seq_len = [len(i.split()) for i in X_train]

pd.Series(seq_len).hist(bins = 30)

tokens_train = tokenizer.batch_encode_plus(
    X_train.tolist(),
    max_length = 30,
    pad_to_max_length=True,
    truncation=True
)

tokens_val = tokenizer.batch_encode_plus(
    X_val.tolist(),
    max_length = 25,
    pad_to_max_length=True,
    truncation=True
)

# tokenize and encode sequences in the test set
tokens_test = tokenizer.batch_encode_plus(
    X_test.tolist(),
    max_length = 25,
    pad_to_max_length=True,
    truncation=True
)

from transformers import BertTokenizer

# Initialize the tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize the training data
tokens_train = tokenizer(X_train.tolist(), padding=True, truncation=True, return_tensors="pt")

# Tokenize the validation data
tokens_val = tokenizer(X_val.tolist(), padding=True, truncation=True, return_tensors="pt")

# Tokenize the test data
tokens_test = tokenizer(X_test.tolist(), padding=True, truncation=True, return_tensors="pt")

from sklearn.preprocessing import LabelEncoder
import torch

# Assuming 'y' is your entire set of labels before splitting
label_encoder = LabelEncoder()

# Fit the encoder on all possible labels
label_encoder.fit(y)

# Now transform the labels into encoded forms after splitting
Y_train_encoded = label_encoder.transform(Y_train)
Y_val_encoded = label_encoder.transform(Y_val)
Y_test_encoded = label_encoder.transform(Y_test)

# Convert these encoded labels to tensors

train_y = torch.tensor(Y_train_encoded, dtype=torch.long)
val_y = torch.tensor(Y_val_encoded, dtype=torch.long)
test_y = torch.tensor(Y_test_encoded, dtype=torch.long)


# Assuming you have tokenized sequences and attention masks for train, val, and test sets
train_seq = tokens_train['input_ids']  # tokens_train is the output of BERTTokenizer
train_mask = tokens_train['attention_mask']

val_seq = tokens_val['input_ids']  # tokens_val is the output of BERTTokenizer
val_mask = tokens_val['attention_mask']

test_seq = tokens_test['input_ids']  # tokens_test is the output of BERTTokenizer
test_mask = tokens_test['attention_mask']

from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler

#define a batch size
batch_size = 32

# wrap tensors
train_data = TensorDataset(train_seq, train_mask, train_y)

# sampler for sampling the data during training
train_sampler = RandomSampler(train_data)

# dataLoader for train set
train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)

# wrap tensors
val_data = TensorDataset(val_seq, val_mask, val_y)

# sampler for sampling the data during training
val_sampler = SequentialSampler(val_data)

# dataLoader for validation set
val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)

for param in bert.parameters():
    param.requires_grad = False

class BERT_Arch(nn.Module):

    def __init__(self, bert):
        super(BERT_Arch, self).__init__()

        self.bert = bert

        # dropout layer
        self.dropout = nn.Dropout(0.1)

        # relu activation function
        self.relu =  nn.ReLU()

        # dense layer 1
        self.fc1 = nn.Linear(768,512)

        # dense layer 2 (Output layer)
        self.fc2 = nn.Linear(512,2)

        #softmax activation function
        self.softmax = nn.LogSoftmax(dim=1)

    #define the forward pass
    def forward(self, sent_id, mask):

        #pass the inputs to the model
        _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)

        x = self.fc1(cls_hs)

        x = self.relu(x)

        x = self.dropout(x)

        # output layer
        x = self.fc2(x)

        # apply softmax activation
        x = self.softmax(x)

        return x

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print('Using device:', device)

model = BERT_Arch(bert)

# push the model to GPU
model = model.to(device)

from transformers import AdamW

# define the optimizer
optimizer = AdamW(model.parameters(),lr = 1e-5)

def train():

    model.train()
    total_loss, total_accuracy = 0, 0

    # empty list to save model predictions
    total_preds=[]

    # iterate over batches
    for step,batch in enumerate(train_dataloader):

        # progress update after every 50 batches.
        if step % 50 == 0 and not step == 0:
            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))

        # push the batch to gpu
        batch = [r.to(device) for r in batch]

        sent_id, mask, labels = batch

        # clear previously calculated gradients
        model.zero_grad()

        # get model predictions for the current batch
        preds = model(sent_id, mask)

        # compute the loss between actual and predicted values
        loss = cross_entropy(preds, labels)

        # add on to the total loss
        total_loss = total_loss + loss.item()

        # backward pass to calculate the gradients
        loss.backward()

        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

        # update parameters
        optimizer.step()

        # model predictions are stored on GPU. So, push it to CPU
        preds=preds.detach().cpu().numpy()

    # append the model predictions
    total_preds.append(preds)

    # compute the training loss of the epoch
    avg_loss = total_loss / len(train_dataloader)

      # predictions are in the form of (no. of batches, size of batch, no. of classes).
      # reshape the predictions in form of (number of samples, no. of classes)
    total_preds  = np.concatenate(total_preds, axis=0)

    #returns the loss and predictions
    return avg_loss, total_preds

def evaluate():

    print("\nEvaluating...")

    # deactivate dropout layers
    model.eval()

    total_loss, total_accuracy = 0, 0

    # empty list to save the model predictions
    total_preds = []

    # iterate over batches
    for step,batch in enumerate(val_dataloader):

        # Progress update every 50 batches.
        if step % 50 == 0 and not step == 0:

            # Calculate elapsed time in minutes.
            elapsed = format_time(time.time() - t0)

            # Report progress.
            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))

        # push the batch to gpu
        batch = [t.to(device) for t in batch]

        sent_id, mask, labels = batch

        # deactivate autograd
        with torch.no_grad():

            # model predictions
            preds = model(sent_id, mask)

            # compute the validation loss between actual and predicted values
            loss = cross_entropy(preds,labels)

            total_loss = total_loss + loss.item()

            preds = preds.detach().cpu().numpy()

            total_preds.append(preds)

    # compute the validation loss of the epoch
    avg_loss = total_loss / len(val_dataloader)

    # reshape the predictions in form of (number of samples, no. of classes)
    total_preds  = np.concatenate(total_preds, axis=0)

    return avg_loss, total_preds

import torch
import torch.nn as nn

# Assuming num_classes is the number of classes in your dataset
num_classes = 350  # Update this with the actual number of classes

# Define the weight tensor for class balancing
class_weights = torch.ones(num_classes)  # Initialize with ones
class_weights = class_weights.to(device)  # Move to the device (CPU or GPU) if necessary

# Assuming you're using nn.CrossEntropyLoss for your loss function
# Pass the class_weights to the weight parameter of nn.CrossEntropyLoss
criterion = nn.CrossEntropyLoss(weight=class_weights)

import torch
import torch.nn as nn

# Assuming num_classes is the number of classes in your dataset
num_classes = 350  # Update this with the actual number of classes

# Define the weight tensor for class balancing
class_weights = torch.ones(num_classes)  # Initialize with ones
class_weights = class_weights.to(device)  # Move to the device (CPU or GPU) if necessary

# Assuming you're using nn.CrossEntropyLoss for your loss function
# Pass the class_weights to the weight parameter of nn.CrossEntropyLoss
criterion = nn.CrossEntropyLoss(weight=class_weights)

# In your training loop, use this criterion for computing the loss
def train():
    model.train()
    total_loss = 0.0
    for batch in train_dataloader:
        inputs, masks, labels = batch
        inputs = inputs.to(device)
        masks = masks.to(device)
        labels = labels.to(device)

        optimizer.zero_grad()
        outputs = model(inputs, masks)
        loss = criterion(outputs, labels)  # Use the defined criterion
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    average_loss = total_loss / len(train_dataloader)
    return average_loss

# get predictions for test data
with torch.no_grad():
    preds = model(test_seq.to(device), test_mask.to(device))
    preds = preds.detach().cpu().numpy()


# model's performance
preds = np.argmax(preds, axis = 1)
print(classification_report(test_y, preds))

